Trabalho-de-Graduacao
	Estudos históricos destacam como grandes invenções da humanidade: a roda, a internet, o motor a vapor e a luz. Porém outras vertentes pontuam a fala como uma das mais importantes invenções da raça humana. Segundo pesquisas realizadas pelo IBGE (significado sigla), no Brasil existem mais de 10 milhões de pessoas com algum grau de deficiência auditiva, que em sua maioria fazem uso e fruto da Libras (Língua Brasileira de Sinais) como principal forma de expressão, sendo ela considerada a segunda língua oficial do país. Buscando uma visão tecnológica do uso da Libras como forma de comunicação, existe uma gama considerável de aplicações que auxiliam pessoas ouvintes a se comunicarem com deficientes auditivos, que proporcionam tradução instantânea da língua portuguesa para a língua de sinais, contudo o contrário não é verídico, hoje encontra-se um déficit de projetos voltados para a transcrição da Libras para a língua falada.
	Assim, este trabalho tem como pilar primordial a utilização de mapeamento de pontos de referência nas mãos visando não utilizar de bases de dados para a realização de treinamentos, identificando padrões e definindo conjuntos de posições dos pontos referidos, também com foco na utilização de recursos de captura de imagem básicos, como câmeras / webcams, garantindo uma solução de baixo custo de implementação. Com isso, almejando realizar a transposição da língua de sinais para o português.

Palavras chave: Comunicação; Língua de Sinais; Aprendizado Profundo; Visão Computacional.

Introdução
	Em 2021, em uma situação hipotética, uma pessoa que necessite descobrir a melhor rota para chegar em um local pode, por intermédio de um comando de voz, pesquisar tal rota e concluir seu objetivo de forma ágil. O mesmo equivale para o envio de um e-mail de suma importância que, com poucos cliques, pode abrir um conversor de fala para texto. Tais atividades só são possível com a evolução do reconhecimento de voz, tecnologia que faz uso de um microfone para poder captar falas e redigi-las em um texto.
	Da mesma forma que o processamento de fala para texto evoluiu ao ponto de ser uma ferramenta corriqueira, o processamento de imagem também alcançou patamares nunca vistos antes, uma câmera ligada consegue fazer o reconhecimento se uma pessoa está ou não usando máscara, com a foto de um rosto é possível saber qual a emoção do indivíduo ou até mesmo identificar a placa de um carro com uma câmera instalada em uma rodovia.
	Estas tecnologias também possuem suas usabilidades mais altruístas, sendo elas no auxílio durante aprendizado de crianças autistas a reconhecer expressões faciais [1], ou uma aplicação que ajuda cegos no reconhecimento de roupas [2], entre inúmeras outras, contudo existe uma lacuna no quesito de inclusão de deficientes auditivos. Existe uma gama considerável de ferramentas que realizam a tradução do português para a Libras (Língua Brasileira de Sinais) de uma forma muito eficiente no amparo de surdos a entender a mensagem de ouvintes que não conhecem linguagem de sinais, entretanto quando há a necessidade de uma forma de compreender uma mensagem dita em Libras isso só pode ocorrer por intermédio de um intérprete ou de uma pessoa que conheça tal dialeto. Em um país que possui uma população de mais de 10 milhões de habitantes que possuem algum tipo de deficiência auditiva, segundo pesquisas realizadas em 2010 pelo IBGE (Instituto Brasileiro de Geografia e Estatística)[3], que em sua maioria fazem uso e fruto da Libras como principal forma de expressão, sendo ela considerada a segunda língua oficial do país, pensando nisso, chega-se a pergunta que orienta este trabalho acadêmico vem à tona da seguinte forma:
	Seria possível um sistema computacional substituir essa necessidade de um intérprete de Libras?
	Para responder esta pergunta, e considerando as limitações na identificação de sinais da Libras, este trabalho tem como objetivo propor a utilização de computação visual no reconhecimento de mãos e seus pontos de referências com a finalidade de transcrever gestos em palavras, inicialmente focando nas 26 letras do alfabeto e números de zero a nove.
	Devido o elevado número de pessoas no Brasil que possuem alguma deficiência auditiva, este trabalho poderá auxiliar em demasiado esta parte da população que é dependente da linguagem de sinais, pois terão uma rota para construir uma comunicação com aqueles desprovidos de qualquer conhecimento em Libras. Ampliando ainda esta visão, pode-se apontar uma quebra na dependência de intérpretes em partições públicas visto que este trabalho apresenta uma solução na compreensão de deficientes auditivos por ouvintes.
	Pelo fato dos autores estudarem em uma instituição de ensino superior pública, onde a preocupação social é abordada constantemente durante o curso, o desenvolvimento de um sistema para este fim vem ao encontro a missão da faculdade, além disso o desenvolvimento deste trabalho acadêmico pode-se tornar uma base para outros estudos, visto que é uma pesquisa sobre processamento de imagens voltado para a área de interpretação de linguagem de sinais, possuindo um reportório de estudos escasso neste campo.
	Para os autores, neste trabalho, destacam-se dois grandes pontos, primeiramente a oportunidade de construir uma ferramenta que possa ampliar a inclusão de pessoas surdas na sociedade quebrando paradigmas que hoje geram um distanciamento destes indivíduos. Em segundo ponto o desafio de implementar uma nova tecnologia, ainda pouco explorada, em uma comunidade que pode obter um ganho incalculável com o sucesso deste trabalho.
	Durante o desenvolvimento do trabalho, realizar-se-á uma pesquisa bibliográfica, principalmente em artigos científicos, dissertações e teses. Os autores ainda irão fazer um levantamento de trabalhos relacionados. Após esta etapa será possível o desenvolvimento de um sistema utilizando da linguagem Python. Ao término do desenvolvimento, o sistema será posto em teste por usuários da Libras que irão responder um formulário com a finalidade de validar o sistema. 
	Portanto, o trabalho será composto da seguinte forma: No capítulo 1, será apresentada uma breve introdução sobre a Libras, assim como um estudo linguístico de suas características e uma contextualização do conceito de computação visual. No capítulo 2, encontram-se as metodologias abordadas, explicando as variáveis propostas para a elaboração do projeto. No capítulo 3, é descrito o processo de desenvolvimento da ferramenta, e no capítulo 4 são exibidos os resultados atingidos com o projeto.

1 - Fundamentações Teóricas

1.1 - História dos Surdos no Brasil
	De acordo com o Strobel (2009)[4], no ano de 1857 foi fundado no Brasil o Instituto Imperial de Surdos-Mudos pelas mãos de Dom Pedro II, em parceria com Ernest Huet, que posteriormente recebeu a alcunha de Instituto Nacional de Educação de Surdos (INES), sediado no Rio de Janeiro. Huet, também conhecido como “pai da Libras”, era um padre francês surdo responsável pela educação da língua de sinais na França. A convite de Dom Pedro II, veio ao Brasil com o propósito de desenvolver uma língua de sinais para os surdos do país. A Língua Brasileira de Sinais (Libras) tem como sua base fonológica uma mescla entre a língua de sinais francesa e características da língua de sinais utilizada pelos surdos brasileiros. O Instituto Imperial tinha como objetivo a educação de meninos surdos da alta classe social.
	Em meados de 1873, é criado no Brasil, pelo Instituto de Surdos-Mudos, a iconografia dos sinais de mão da Libras para as letras do alfabeto, por autoria de Flausino José de Gama, aluno surdo do instituto. E após 7 anos, ou seja, em 1880, ocorre o Congresso de Milão que foi uma conferência internacional de educadores de surdos, marcando a história do ensino de pessoas com deficiência auditiva ao definir a oralidade como melhor método de aprendizado em detrimento das línguas gestuais de forma obrigatória aos países participantes, com duração aproximada a 100 anos. Tal ação foi vista com maus olhos pela cultura surda, já que endossavam a língua de sinais como forma de comunicação, o que levou a diversos movimentos contra esta decisão e houveram muitas pesquisas na área com a finalidade de legitimar a linguagem gestual.
	Este congresso teve um reflexo muito negativo na educação de surdos no Brasil. O INES recebeu uma proibição para educar os surdos no dialeto de Libras, o que acarretou em uma baixa na quantidade de professores surdos nas escolas para deficientes auditivos, tendo suas vagas preenchidas por professores ouvintes. Por volta da década de 30, vários ex-estudantes do INES fundaram a primeira Associação Brasileira de Surdos-Mudos, hoje já inativa. Entre os anos de 1953 e 1956, foram fundadas outras 3 Associações de Surdos, que tiveram papéis importantes na vivência de pessoas com deficiência auditiva no país. Por intermédio destas associações, outras unidades foram fundadas em vários estados do Brasil. A Federação Nacional de Educação e Integração de Surdos (FENEIS), organização filantrópica sem fins lucrativos que luta pela inclusão dos surdos e garantia de seus direitos, teve origem no ano de 1987.
	Na década de 90, a história dos surdos recebe um destaque em diversos eventos bilinguísticos (Língua de Sinais e Língua Oral) que ocorreram por todo o país, por intermédio de Universidades Federais com parceria de professores de diversos países, que ministraram cursos de metodologias de ensino de suas respectivas línguas de sinais. No final da década ocorre um congresso de extrema importância para a história da Libras: o V Congresso Latino Americano de Educação Bilíngue para Surdos, onde uma das pautas de debate era a formação de professores surdos e intérpretes de Libras.
	O resultado destes esforços combinados serviu como base para o início dos projetos de lei que regularizavam a Libras no Congresso, tendo seu início no ano de 1993. Foi somente no ano de 2002, mais especificamente no dia 24 de abril, que entrava em vigor a lei nº 10.436/02 [5], reconhecendo a Libras oficialmente no país, esta data ganhou grande valor para a cultura surda tornando-se reconhecida como Dia Nacional da Língua Brasileira de Sinais.
	Nos treze anos seguintes várias outras leis surgiram com o objetivo de fortalecer ainda mais a lei do ano de 2002, contudo todos estes esforços realizados não foram suficientes para garantir uma inclusão efetiva de pessoas surdas na sociedade. Mesmo sendo considerada a segunda língua oficial do país, grande parte da população ouvinte não possui os conhecimentos desta linguagem, o que dificulta o convívio diário entre os grupos e consequentemente reforça a exclusão dos não-ouvintes da sociedade.


1.2 - Lingua Brasileira de Sinais (Libras) e sua fonologia
	A definição de linguagem natural pode ser concebida como qualquer meio de comunicação desenvolvido naturalmente com a finalidade de promover a troca de informações entre seus usuários, com um conjunto limitado de componentes que permite a criação de sentenças infinitas ao uso. Tais linguagens diferem, por exemplo, das linguagens de programação de computadores, ao terem seu aprendizado por meio do convívio social dos indivíduos. Seguindo esta definição, pode-se construir um paralelo com as linguagens de sinais para com a sociedade dos surdos, visto que seus usuários possuem a capacidade de contruir uma quantidade ilimitada de expressões utilizando o conjunto de funções e movimentos disponibilizados pela língua. (FONSECA, 2020)[6]
	De forma similar às demais linguagens de sinais existentes, a Libras tem sua estrutura modal baseada no princípio gestual-visual, onde faz uso de movimentos gestuais e/ou expressões faciais para transmitir uma mensagem, e a forma de recebê-la vem por intermédio da visão, o que difere da língua falada que tem como fundamentos de transmissão a fala (envio) e a audição (recepção). Entretanto, tais diferenças não se encontram única e exclusivamente em seus canais de difusão, mas também em suas estruturas gramaticais.
	Fonologia, do grego phonos (som) e logos (estudo), é o estudo da linguagem sonora de um idioma visando estruturar e organizar os componentes nas quais, isoladamente, não possuem significado.[7] A Libras, por sua vez, possui suas próprias regras fonológicas devido ao fato de ser uma língua espaço-visual, sendo elas definidas em cinco vertentes principais: configuração das mãos, movimento, ponto de articulação, orientação da mão e expressão facial e/ou corporal.
	A seguir serão divididos em cinco subsessões as definições citadas acima.

1.2.1 - Configuração das mãos
	Consiste na forma como a mão é configurada, podendo fazer uso ou não de ambas as mãos, porém algumas não transmitem significados isoladamente pois necessitam dos outros parâmetros para seu entendimento, já outras assumem as formas das letras do alfabeto. Fontes de pesquisa, porém, divergem quando se trata da quantia exata de configurações existentes. De acordo com CRUZ (2020)[8], são presentes 73 configurações de mãos na Libras, conforme a Figura 1. Para Tanya e Myrna (2007, p. 28)[9], existem 64 parâmetros, como demonstrado na Figura 2.

Figura 1: Configurações de mão extraídas do Dicionário Digital da INES
[FIGURA]
Fonte: Cruz, 2020, p.12 apud Lira e Souza, 2018

Figura 2: Configuração de Mão da Libras
[FIGURA]
Fonte: Felipe e Monteiro, 2007, p.28 

1.2.2 - Movimento
	No parâmetro de movimento, sinais podem ser subdivididos em dois grupos: sinais estáticos, aqueles que não fazem uso de movimentos das mãos para serem executados, e sinais dinâmicos, que necessitam da movimentação das mãos. A forma da movimentação das mãos não implica só na execução dos sinais, mas também na intensidade na qual são expressados, no modo adverbial ou em sua temporalidade. (CRUZ, 2020) Exemplos de sinais que utilizam movimento estão dispostos na Figura 3.

Figura 3: Representação do parâmetro “movimento”
[FIGURA]
Fonte: Cruz, 2020, p.14 apud Felipe e Monteiro, 2007

1.2.3 - Pontos de articulação
	A utilização dos pontos de articulação baseia-se na predominância do local aonde o sinal de mão é realizado, podendo ser estes em áreas neutras (região em frente ao tronco), ou que faz uso de alguma parte do corpo para sua realização, como por exemplo a àrea da cabeça/rosto, ou a área dos membros. Um exemplo que diferencia sinais com a mesma configuração de mão baseado no ponto de articulação encontra-se na Figura 4.

Figura 4: Representação do parâmetro “ponto de articulação”
[FIGURA]
Fonte: Cruz, 2020, p.13 apud Felipe e Monteiro, 2007

1.2.4 - Orientação da mão
	Expressa o sentido na qual a mão segue em casos de sinais que requerem movimentos direcionáveis. Tais orientações podem expressar oposição de sentido, mesmo com a realização de movimentos e configuração de mãos similares. Exemplos disponíveis na Figura 5.

Figura 5: Representação do parâmetro “orientação”
[FIGURA]
Fonte: Cruz, 2020, p.14 apud Felipe e Monteiro, 2007

1.2.5 - Expressões
	Nos parâmetros citados acima, há a predominância do uso das mãos para sua execução, contudo alguns sinais também podem fazer uso de expressões faciais e/ou corporais para expor significado ou intensidade. Na Libras, porém, existem sinais / expressões que não utilizam das mãos para sua realização, dependendo de expressões para sua transmissão.

Figura 6: Representação do parâmetro “expressão”
[FIGURA]
Fonte: Cruz, 2020, p.15 apud Felipe e Monteiro, 2007


2 - Metodologia
	Neste capítulo são abordadas as ferramentas utilizadas na implementação deste projeto, como por exemplo o OpenCV, MediaPipe, Tensorflow, entre outros. Também será descrita a metodologia a ser aplicada durante a fase de desenvolvimento, buscando referências em trabalhos relacionados na área de pesquisa.

2.1 - OpenCV
	O OpenCV (Open Sourcer Computer Vision)(OpenCV, s.d.)[10], desenvolvido pela Intel Corporation, é uma biblioteca 'open source' de programação que implementa diversas ferramentas de apoio à interpretação de imagens de forma computacional. (MARENGONI e STRINGHINI, 2009)[11] Com esta ferramenta, é possível realizar o processamento de imagens em vários níveis, desde a aplicação de filtros simples até funções mais complexas de reconhecimento e análise da captura, visando a acessibilidade de programadores à tecnologias de robótica e interações em tempo real humano-máquina.
Segundo Marengoni e Stringhini (2009 apud Gonzalez et al., 2006)[11] pode-se dividir em três níveis (baixo-nível, nível-médio e alto-nível) o espectro entre processamento de imagem e a visão computacional:
	"Os processos de baixo-nível envolvem operações primitivas, tais como a redução de ruído ou melhoria no contraste de uma imagem. Os processos de nível-médio são operações do tipo segmentação (particionamento da imagem em regiões) 	ou classificação (reconhecimento dos objetos na imagem). Os processos de altonível estão relacionados com as tarefas de cognição associadas com a visão humana."

2.2 - Tensorflow
	Ferramenta desenvolvida pela Google, Tensorflow (Tensorflow, s.d.)[12] é uma biblioteca de código aberto utilizada em sistemas de aprendizado de máquina, responsável por disponibilizar ferramentas de gerência do processamento dos algorítmos através de CPUs (Central Processing Units), GPUs (Graphics Processing Units) e TPUs (Tensor Processing Units).(MARTINS, 2021)[13] A biblioteca disponibiliza funções de suporte para treino de modelos de aprendizagem, tendo o Python como sua linguagem de programação principal, mas também possuindo suporte oficial para linguagens como JavaScript, Java, C++, entre outras. (NOGUEIRA, 2020)[14]

2.3 - MediaPipe
	(Os artigos que li não falaram profundamente sobre MediaPipe, somente citações. Deixei o tópico aqui no meio, mas se necessário alterar, sem problemas)

2.4 - Redes Neurais Artificiais (ANN)
	Segundo CRUZ (2020 apud Goodfellow et al., 2016)[8] pode-se definir o conceito de redes neurais artificiais como:
	"Desse modo, redes neurais artificiais são modelos computacionais inspirados no sistema nervoso central animal, capazes de reconhecer padrões e aprender por meio de dados e experiência."
	As redes neurais são compostas por três tipos principais de camadas, ilustradas na Figura 7:
	- Camada de entrada - responsável pelo recebimento dos dados de entrada e inicia o processamento das informações. 
	- Camadas ocultas - realizam os principais cálculos e funções para agregar os dados, prepará-los e direcioná-los à saída.
	- Camada de saída - calcula a previsão final do método. (MARTINS, 2021)[13]

Figura 7: Rede Neuronal Artificial
[FIGURA]
Fonte: Martins, 2021, p.6 apud Basak, 2018


LISTA DE FIGURAS

Figura 1: Configurações de mão extraídas do Dicionário Digital da INES........xx
Figura 2: Configuração de Mão da Libras.......................................xx
Figura 3: Representação do parâmetro “movimento”..............................xx
Figura 4: Representação do parâmetro “ponto de articulação”...................xx
Figura 5: Representação do parâmetro “orientação”.............................xx
Figura 6: Representação do parâmetro “expressão”..............................xx
Figura 7: Rede Neuronal Artificial............................................xx



REFERÊNCIAS
<rever formatação> [1 (Introdução)] Disponível em: <https://www.noticias.unb.br/publicacoes/117-pesquisa/119-tecnologia-ajuda-autistas-a-identificar-expressoes-faciais#:~:text=A%20ferramenta%20de%20apoio%20pedag%C3%B3gico,que%20requer%20trabalho%20educacional%20espec%C3%ADfico.&text=O%20objetivo%20%C3%A9%20que%20o,express%C3%B5es%20nos%20ambientes%20que%20frequenta.>
Acesso em: 07 ago. 2021.

<rever formatação> [2 (Introdução)] Disponível em: <https://www.redalyc.org/journal/3131/313158902036/html/>
Acesso em: 07 ago. 2021.

[3 (Introdução)] Disponível em: <https://www.ibge.gov.br/apps/snig/v1/?loc=0&cat=-1,-2,-3,128&ind=4643>
Acesso em: 07 ago. 2021.

[4 (1.1)] STROBEL, Karin. HISTÓRIA DA EDUCAÇÃO DE SURDOS. 2009. 49p. Licenciatura (Letras-LIBRAS na modalidade a distância) - UFSC (Universidade Federal de Santa Catarina), Florianópolis.

[5 (1.1)] Dispõe sobre a Língua Brasileira de Sinais - Libras e dá outras providências. Disponível em: <http://www.planalto.gov.br/ccivil_03/leis/2002/l10436.htm>
Acesso em: 07 ago. 2021.

[6 (1.2)] FONSECA, Fabiana Ferreira. VISAO COMPUTACIONAL APLICADA AO RECONHECIMENTO DE IMAGENS RELACIONADAS À LÍNGUA BRASILEIRA DE SINAIS. 2020. 105p. Monografia (Engenharia Eletrônica e de Computação) - Escola Politécnica, UFRJ (Universidade Federal do Rio de Janeiro), Rio de Janeiro.

[7 (1.2)] Editora Melhoramentos Ltda. Dicionário Brasileiro da Língua Portuguesa. Disponível em: <https://michaelis.uol.com.br/moderno-portugues/busca/portugues-brasileiro/fonologia>
Acesso em: 15 ago. 2021.

[8 (1.2; 2.4)] CRUZ, Ada Raquel dos Santos. UMA ESTRATÉGIA PARA RECONHECIMENTO DE SINAIS DA LÍNGUA BRASILEIRA DE SINAIS UTILIZANDO APRENDIZADO PROFUNDO. 2020. 78p. Dissertação (Mestre em Informática) - Instituto de Computação - UFAM (Universidade Federal do Amazonas), Manaus.

[9 (1.2)] FELIPE, Tanya A.; MONTEIRO, Myrna Salerno S. Libras em Contexto: Curso Básico: Livro do Professor. 6. ed. Brasília:MEC, 2007.

[10 (2.1)] OpenCV. Disponível em: <http://sourceforge.net/projects/opencvlibrary>
Acesso em: 07 set. 2021.

[11 (2.1)] MARENGONI, Maurício; STRINGHINI, Denise. Tutorial: Introdução à Visão Computacional usando OpenCV. 2009. (É UM LIVRO, REVER REFERÊNCIA) 

[12 (2.2)] Tensorflow. Disponível em: <https://www.tensorflow.org/>
Acesso em: 07 set. 2021.

[13 (2.2)] MARTINS, Ricardo A. S. Sistema de contagem de pessoas na biblioteca da FEUP utilizando visão computacional. 2021. 96p. Mestrado Integrado (Engenharia Eletrotécnica e de Computadores) - Faculdade de Engenharia, FEUP (Universidade do Porto), Porto, Portugal.

[14 (2.2)] NOGUEIRA, André. SignPic: Sistema Móvel Para Deteção de Língua Gestual Utilizando Machine Learning. 2020. 55p.  (Master of Science) - Faculdade de Ciências e Tecnologia, UFP (Universidade Fernando Pessoa), Porto, Portugal.

[15 ()] 

[16 ()] 

[17 ()] 


